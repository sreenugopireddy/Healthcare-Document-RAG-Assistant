# ğŸ¥ Healthcare Document RAG Assistant  
### A Modular Retrieval-Augmented Generation System for Medical Knowledge QA

The Healthcare Document RAG Assistant is a domain-specific question answering system built using a Retrieval-Augmented Generation (RAG) pipeline. It allows users to query healthcare documents and receive context-grounded answers generated by a Large Language Model (LLM).

Instead of relying only on model memory, the system retrieves semantically relevant passages from indexed medical PDFs and conditions the LLM response strictly on that retrieved context. This reduces hallucinations and improves answer traceability, which is critical in healthcare scenarios.

The project demonstrates a full end-to-end RAG workflow including document ingestion, chunking, embedding generation, FAISS vector indexing, semantic retrieval, guarded prompt construction, and source-attributed answer generation through an interactive interface.

---

# ğŸš€ Features

âœ… Healthcare PDF document ingestion  
âœ… Intelligent text chunking with overlap  
âœ… Transformer-based embeddings  
âœ… FAISS semantic vector search  
âœ… Top-K context retrieval  
âœ… Context-grounded LLM answers  
âœ… Guarded prompt templates  
âœ… Source citation with answers  
âœ… Refusal when evidence not found  
âœ… Medical safety disclaimer  
âœ… Modular RAG pipeline design  
âœ… Interactive query interface  

---

# ğŸ§  Tech Stack

| Layer | Technology |
|--------|------------|
Language | Python |
Framework | LangChain |
Vector Database | FAISS |
Embeddings | Sentence Transformer |
LLM | Groq LLaMA |
Interface | Streamlit |
Document Input | PDF |
Env Management | python-dotenv |

---

# ğŸ—ï¸ System Architecture

The system uses a two-stage RAG architecture separating offline indexing from online query answering.

## Offline Indexing Pipeline

```
Healthcare PDFs
 â†’ Document Loader
 â†’ Text Cleaning
 â†’ Chunking + Overlap
 â†’ Embedding Generation
 â†’ FAISS Vector Index
```

## Online Query Pipeline

```
User Query
 â†’ Query Preprocessing
 â†’ Query Embedding
 â†’ Top-K Vector Retrieval
 â†’ Context Assembly
 â†’ Guarded Prompt Builder
 â†’ LLM Generation
 â†’ Answer + Source Citations
```

This separation allows knowledge base updates without modifying runtime generation logic.

---

# ğŸ“‚ Project Structure

```text
Healthcare-Document-RAG-Assistant/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ ingestion.py
â”œâ”€â”€ retrieval.py
â”œâ”€â”€ prompt_builder.py
â”œâ”€â”€ config.py
â”‚
â”œâ”€â”€ data/                 # healthcare PDFs
â”œâ”€â”€ embeddings/           # FAISS index
â”œâ”€â”€ screenshots/          # UI images
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

# ğŸ“¥ Document Ingestion

- PDFs are parsed into text
- Noise and formatting artifacts reduced
- Text split into semantic chunks
- Overlap preserves context continuity
- Each chunk embedded into vector space
- Stored in FAISS index with metadata

## Chunking Strategy

- Chunk size tuned for semantic completeness  
- Overlap prevents boundary information loss  
- Source metadata retained for citation  

---

# ğŸ” Retrieval Strategy

Semantic similarity search is used for retrieval.

- Query embedded using same embedding model
- FAISS nearest-neighbor search
- Top-K chunks selected
- Similarity score filtering applied
- Retrieved passages shown as sources

Planned upgrades:

- Hybrid keyword + vector retrieval  
- Re-ranking layer  
- Metadata filtering  

---

# ğŸ§  Prompt Engineering & Guardrails

Guarded prompts enforce safe generation behavior:

- Answer only from retrieved context
- Refuse when evidence missing
- No speculative medical advice
- Structured answer format
- Source-grounded responses

Example rule:

```
Answer only using provided medical context.
If not found, respond: Not available in documents.
```

---

# ğŸ›¡ï¸ Safety Controls

Because this is a healthcare domain system:

- Context-grounded generation only  
- Refusal behavior for unsupported queries  
- Medical disclaimer shown  
- No diagnosis or prescription claims  
- Source traceability enforced  

---

# ğŸ“Š Retrieval Evaluation

Evaluation focused on retrieval relevance and grounding.

## Evaluation Checks

- Top-K relevance inspection  
- Context-answer alignment  
- Paraphrase query stability  
- Similarity score validation  
- Manual grounding verification  

## Observations

- Semantic retrieval stable across paraphrases  
- Chunk overlap improves completeness  
- Guarded prompts reduce hallucination  
- Refusal behavior works correctly  

## Planned Metrics

- Precision@K  
- Recall@K  
- Mean Reciprocal Rank (MRR)  
- Automated benchmark queries  

---

# ğŸš€ Setup Instructions

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/sreenugopireddy/Healthcare-Document-RAG-Assistant.git
cd Healthcare-Document-RAG-Assistant
```

---

## 2ï¸âƒ£ Create Virtual Environment

### Windows
```bash
python -m venv venv
venv\Scripts\activate
```

### Mac/Linux
```bash
python3 -m venv venv
source venv/bin/activate
```

---

## 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## 4ï¸âƒ£ Configure Environment Variables

Create `.env` file:

```env
GROQ_API_KEY=your_key_here
```

---

## â–¶ï¸ Run Application

```bash
streamlit run app.py
```

Open the local Streamlit URL in your browser.

---

# ğŸ“¸ Interface

The interface supports:

- Natural language healthcare queries  
- Context-grounded answers  
- Source document references  
- Safety disclaimer display  

---

# ğŸ”§ Maintenance & Support

- Re-run ingestion when adding documents  
- Rebuild embeddings after corpus updates  
- Version prompt templates  
- Periodic retrieval quality checks  
- Dependency version pinning  
- Guardrail tuning over time  

---

# ğŸ§ª Future Improvements

- Automated retrieval metrics  
- Query re-ranking  
- Hybrid retrieval  
- Ontology-aware indexing  
- Feedback-driven tuning  
- Larger medical corpus  

---

# âš ï¸ Disclaimer

This system is for educational and technical demonstration purposes only. It does not provide medical diagnosis or treatment advice.

---

# ğŸ“œ License

MIT License â€” see LICENSE file for details.

---

# ğŸ‘¤ Author

**Sreenivasa Reddy**

---

# ğŸ¤ Contributions

Pull requests are welcome. Please open an issue first to discuss major changes.

---
